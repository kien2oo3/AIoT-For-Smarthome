# import os
# import face_recognition
# import pickle
# import numpy as np
#
# # Th∆∞ m·ª•c ch·ª©a ·∫£nh khu√¥n m·∫∑t
# data_dir = "dataimage/"
#
# # Danh s√°ch l∆∞u ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t v√† nh√£n
# known_face_encodings = []
# known_face_names = []
#
# # Qu√©t t·∫•t c·∫£ th∆∞ m·ª•c trong dataimage (m·ªói th∆∞ m·ª•c l√† t√™n c·ªßa 1 ng∆∞·ªùi)
# for person_name in os.listdir(data_dir):
#     person_dir = os.path.join(data_dir, person_name)
#     encodings = []
#
#     # Duy·ªát t·∫•t c·∫£ ·∫£nh trong th∆∞ m·ª•c c·ªßa t·ª´ng ng∆∞·ªùi
#     for img_name in os.listdir(person_dir):
#         img_path = os.path.join(person_dir, img_name)
#
#         # ƒê·ªçc ·∫£nh v√† tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t
#         image = face_recognition.load_image_file(img_path)
#         face_enc = face_recognition.face_encodings(image)
#
#         if face_enc:  # Ch·ªâ l·∫•y n·∫øu ph√°t hi·ªán khu√¥n m·∫∑t
#             encodings.append(face_enc[0])
#
#     if encodings:
#         # T√≠nh vector trung b√¨nh ƒë·ªÉ m√¥ h√¨nh nh·∫≠n di·ªán ch√≠nh x√°c h∆°n
#         avg_encoding = np.mean(encodings, axis=0)
#         known_face_encodings.append(avg_encoding)
#         known_face_names.append(person_name)
#
# # L∆∞u model v√†o file
# with open("face_model.pkl", "wb") as f:
#     pickle.dump((known_face_encodings, known_face_names), f)
#
# print(f"Training ho√†n t·∫•t! ƒê√£ l∆∞u {len(known_face_names)} khu√¥n m·∫∑t v√†o 'face_model.pkl'")
#
#
#

# import os
# import face_recognition
# import pickle
# import numpy as np
#
# # Th∆∞ m·ª•c ch·ª©a ·∫£nh ƒë√£ l·ªçc
# data_dir = "dataimage_filtered_clean"
#
# # Danh s√°ch l∆∞u ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t v√† t√™n
# known_face_encodings = []
# known_face_names = []
#
# print("üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh nh·∫≠n di·ªán khu√¥n m·∫∑t...")
# print(f"üìÅ ƒê·ªçc d·ªØ li·ªáu t·ª´: {data_dir}")
#
# # Duy·ªát t·ª´ng ng∆∞·ªùi
# for person_name in os.listdir(data_dir):
#     person_dir = os.path.join(data_dir, person_name)
#     if not os.path.isdir(person_dir):
#         continue
#
#     print(f"üß† X·ª≠ l√Ω: {person_name}")
#     encodings = []
#
#     for img_name in os.listdir(person_dir):
#         img_path = os.path.join(person_dir, img_name)
#         try:
#             image = face_recognition.load_image_file(img_path)
#             face_enc = face_recognition.face_encodings(image)
#
#             if face_enc:
#                 encodings.append(face_enc[0])
#         except Exception as e:
#             print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω ·∫£nh {img_name}: {e}")
#
#     if encodings:
#         avg_encoding = np.mean(encodings, axis=0)
#         known_face_encodings.append(avg_encoding)
#         known_face_names.append(person_name)
#         print(f"‚úÖ {person_name}: {len(encodings)} encoding h·ª£p l·ªá")
#     else:
#         print(f"‚ùå {person_name}: Kh√¥ng c√≥ encoding h·ª£p l·ªá n√†o")
#
# # L∆∞u m√¥ h√¨nh
# with open("face_model.pkl", "wb") as f:
#     pickle.dump((known_face_encodings, known_face_names), f)
#
# print("\nüéâ Hu·∫•n luy·ªán ho√†n t·∫•t!")
# print(f"üì¶ M√¥ h√¨nh l∆∞u t·∫°i: face_model.pkl")
# print(f"üë• T·ªïng s·ªë ng∆∞·ªùi nh·∫≠n di·ªán: {len(known_face_names)}")
# for name in known_face_names:
#     print(f"   - {name}")

# trainmodel_final.py ‚Äî Hu·∫•n luy·ªán m√¥ h√¨nh nh·∫≠n di·ªán khu√¥n m·∫∑t chu·∫©n nh·∫•t

# import os
# import face_recognition
# import pickle
# import numpy as np
# import random
#
# # === C·∫§U H√åNH ===
# data_dir = "dataimage_filtered_clean"  # Th∆∞ m·ª•c ch·ª©a c√°c th∆∞ m·ª•c ng∆∞·ªùi d√πng
# model_output = "face_model.pkl"
# max_encodings_per_person = 60  # S·ªë vector encoding t·ªëi ƒëa m·ªói ng∆∞·ªùi
#
# # === BI·∫æN K·∫æT QU·∫¢ ===
# known_face_encodings = []
# known_face_names = []
#
# print("üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh nh·∫≠n di·ªán khu√¥n m·∫∑t...")
# print(f"üìÅ ƒê·ªçc ·∫£nh t·ª´ th∆∞ m·ª•c: {data_dir}")
#
# # === X·ª¨ L√ù T·ª™NG NG∆Ø·ªúI ===
# for person_name in os.listdir(data_dir):
#     person_dir = os.path.join(data_dir, person_name)
#     if not os.path.isdir(person_dir):
#         continue
#
#     print(f"\nüß† X·ª≠ l√Ω ng∆∞·ªùi: {person_name}")
#     encodings = []
#
#     for img_name in os.listdir(person_dir):
#         img_path = os.path.join(person_dir, img_name)
#         try:
#             image = face_recognition.load_image_file(img_path)
#             face_enc = face_recognition.face_encodings(image)
#
#             if face_enc:
#                 encodings.append(face_enc[0])
#         except Exception as e:
#             print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω ·∫£nh {img_name}: {e}")
#
#     if encodings:
#         random.shuffle(encodings)  # Tr·ªôn ng·∫´u nhi√™n ƒë·ªÉ tr√°nh l·ªách theo th·ª© t·ª± ·∫£nh
#         selected_encodings = encodings[:min(max_encodings_per_person, len(encodings))]
#
#         known_face_encodings.extend(selected_encodings)
#         known_face_names.extend([person_name] * len(selected_encodings))
#
#         print(f"‚úÖ {person_name}: ƒë√£ l∆∞u {len(selected_encodings)} vector encoding")
#     else:
#         print(f"‚ùå {person_name}: kh√¥ng c√≥ encoding h·ª£p l·ªá")
#
# # === L∆ØU M√î H√åNH ===
# with open(model_output, "wb") as f:
#     pickle.dump((known_face_encodings, known_face_names), f)
#
# # === T·ªîNG K·∫æT ===
# print("\nüéâ Hu·∫•n luy·ªán ho√†n t·∫•t!")
# print(f"üì¶ M√¥ h√¨nh ƒë√£ l∆∞u v√†o: {model_output}")
# print(f"üë• T·ªïng s·ªë ng∆∞·ªùi: {len(set(known_face_names))}")
# for name in set(known_face_names):
#     print(f"   - {name}: {known_face_names.count(name)} vector")
# print(f"üß† T·ªïng s·ªë vector: {len(known_face_encodings)}")

import os
import face_recognition
import pickle
import numpy as np
import random
from PIL import Image
import cv2

# === C·∫§U H√åNH ===
data_dir = "dataimage_filtered_clean"  # Th∆∞ m·ª•c ch·ª©a ·∫£nh hu·∫•n luy·ªán
model_output = "face_model.pkl"
max_encodings_per_person = 100  # S·ªë encoding t·ªëi ƒëa m·ªói ng∆∞·ªùi

# === BI·∫æN L∆ØU TR·ªÆ ===
known_face_encodings = []
known_face_names = []

print("üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh nh·∫≠n di·ªán khu√¥n m·∫∑t...")
print(f"üìÅ ƒê·ªçc d·ªØ li·ªáu t·ª´ th∆∞ m·ª•c: {data_dir}")

# === V√íNG L·∫∂P QUA T·ª™NG NG∆Ø·ªúI ===
for person_name in os.listdir(data_dir):
    person_dir = os.path.join(data_dir, person_name)
    if not os.path.isdir(person_dir):
        continue

    print(f"\nüß† X·ª≠ l√Ω ng∆∞·ªùi: {person_name}")
    encodings = []

    for img_name in os.listdir(person_dir):
        img_path = os.path.join(person_dir, img_name)

        try:
            # ƒê·ªçc v√† resize nh·∫π ·∫£nh ƒë·ªÉ ·ªïn ƒë·ªãnh
            image = face_recognition.load_image_file(img_path)

            # Ph√°t hi·ªán khu√¥n m·∫∑t
            face_locs = face_recognition.face_locations(image)
            if len(face_locs) != 1:
                print(f"‚ö†Ô∏è B·ªè qua {img_name} ‚Äì ph√°t hi·ªán {len(face_locs)} khu√¥n m·∫∑t")
                continue

            face_enc = face_recognition.face_encodings(image, face_locs)
            if face_enc:
                encodings.append(face_enc[0])

        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω ·∫£nh {img_name}: {e}")

    if encodings:
        # Random + gi·ªõi h·∫°n s·ªë l∆∞·ª£ng encoding/ng∆∞·ªùi
        random.shuffle(encodings)
        selected_encodings = encodings[:min(max_encodings_per_person, len(encodings))]

        known_face_encodings.extend(selected_encodings)
        known_face_names.extend([person_name] * len(selected_encodings))

        print(f"‚úÖ {person_name}: ƒë√£ l∆∞u {len(selected_encodings)} vector encoding")
    else:
        print(f"‚ùå {person_name}: kh√¥ng c√≥ encoding h·ª£p l·ªá n√†o")

# === L∆ØU M√î H√åNH RA FILE ===
with open(model_output, "wb") as f:
    pickle.dump((known_face_encodings, known_face_names), f)

# === T·ªîNG K·∫æT ===
print("\nüéâ Hu·∫•n luy·ªán ho√†n t·∫•t!")
print(f"üì¶ M√¥ h√¨nh ƒë√£ l∆∞u t·∫°i: {model_output}")
print(f"üë• T·ªïng s·ªë ng∆∞·ªùi: {len(set(known_face_names))}")
for name in set(known_face_names):
    print(f"   - {name}: {known_face_names.count(name)} vector")
print(f"üß† T·ªïng s·ªë vector encoding: {len(known_face_encodings)}")




